{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_reader_remove:\n",
    "    def __init__(self, dataset):\n",
    "        if dataset =='opp':\n",
    "            self.data, self.idToLabel = self.readOpportunity()\n",
    "            self.save_data_csv(dataset)\n",
    "            self.save_data(dataset)\n",
    "        else:\n",
    "            print('Not supported yet')\n",
    "            sys.exit(0)\n",
    "\n",
    "    def save_data_csv(self, dataset):\n",
    "        if dataset == 'opp':\n",
    "            for key in self.data:\n",
    "                for field in self.data[key]:\n",
    "                    np.savetxt('data_ori_'+key+field+'.csv', self.data[key][field], delimiter=',')\n",
    "                    print(key+field,self.data[key][field].shape)\n",
    "            print('Saved in csv.')\n",
    "        else:\n",
    "            print('Not supported yet')\n",
    "            sys.exit(0)\n",
    "\n",
    "    def save_data(self, dataset):\n",
    "        if dataset == 'opp':\n",
    "            f = h5py.File('opportunity.h5')\n",
    "            for key in self.data:\n",
    "                f.create_group(key)\n",
    "                for field in self.data[key]:\n",
    "                    f[key].create_dataset(field, data=self.data[key][field])\n",
    "            f.close()\n",
    "            print('Done.')\n",
    "        else:\n",
    "            print('Not supported yet')\n",
    "            sys.exit(0)\n",
    "\n",
    "    @property\n",
    "    def train(self):\n",
    "        return self.data['train']\n",
    "\n",
    "    @property\n",
    "    def test(self):\n",
    "        return self.data['test']\n",
    "\n",
    "    def readOpportunity(self):\n",
    "        files = {\n",
    "            'train': ['S1-ADL1.dat','S1-ADL3.dat', 'S1-ADL4.dat', 'S1-ADL5.dat', 'S1-Drill.dat', 'S2-ADL1.dat', 'S2-ADL2.dat', 'S2-ADL5.dat', 'S2-Drill.dat', 'S3-ADL1.dat', 'S3-ADL2.dat', 'S3-ADL5.dat', 'S3-Drill.dat', 'S4-ADL1.dat', 'S4-ADL2.dat', 'S4-ADL3.dat', 'S4-ADL4.dat', 'S4-ADL5.dat', 'S4-Drill.dat'],\n",
    "            'test': ['S2-ADL3.dat', 'S2-ADL4.dat','S3-ADL3.dat', 'S3-ADL4.dat']\n",
    "        }\n",
    "        #names are from label_legend.txt of Opportunity dataset\n",
    "        #except 0-ie Other, which is an additional label\n",
    "        label_map = [\n",
    "            (0,      'Other'),\n",
    "            (406516, 'Open Door 1'),\n",
    "            (406517, 'Open Door 2'),\n",
    "            (404516, 'Close Door 1'),\n",
    "            (404517, 'Close Door 2'),\n",
    "            (406520, 'Open Fridge'),\n",
    "            (404520, 'Close Fridge'),\n",
    "            (406505, 'Open Dishwasher'),\n",
    "            (404505, 'Close Dishwasher'),\n",
    "            (406519, 'Open Drawer 1'),\n",
    "            (404519, 'Close Drawer 1'),\n",
    "            (406511, 'Open Drawer 2'),\n",
    "            (404511, 'Close Drawer 2'),\n",
    "            (406508, 'Open Drawer 3'),\n",
    "            (404508, 'Close Drawer 3'),\n",
    "            (408512, 'Clean Table'),\n",
    "            (407521, 'Drink from Cup'),\n",
    "            (405506, 'Toggle Switch')\n",
    "        ]\n",
    "        labelToId = {str(x[0]): i for i, x in enumerate(label_map)}\n",
    "        idToLabel = [x[1] for x in label_map]\n",
    "\n",
    "        cols = [\n",
    "            37, 38, 39, 40, 41, 42, 43, 44, 45, 50, 51, 52, 53, 54, 55, 56, 57, 58,63, 64, 65, 66, 67, 68, 69, 70, 71, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
    "            89, 90, 91, 92, 93, 94, 95, 96, 97, 102, 103, 104, 105, 106, 107, 108,109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
    "            124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 249\n",
    "            ]\n",
    "\n",
    "        data = {dataset: self.readOpportunityFiles(files[dataset], cols, labelToId)\n",
    "                for dataset in ('train', 'test')}\n",
    "\n",
    "        return data, idToLabel\n",
    "\n",
    "#this is from https://github.com/nhammerla/deepHAR/tree/master/data and it is an opportunity Challenge reader. It is a python translation one\n",
    "#for the official one provided by the dataset publishers in Matlab.\n",
    "    def readOpportunityFiles(self, filelist, cols, labelToId):\n",
    "        data = []\n",
    "        labels = []\n",
    "        for i, filename in enumerate(filelist):\n",
    "            print('Reading file %d of %d' % (i+1, len(filelist)))\n",
    "            with open('/Users/JinWei/Downloads/OpportunityUCIDataset/dataset/%s' % filename, 'r') as f:\n",
    "                reader = csv.reader(f, delimiter=' ')\n",
    "                for line in reader:\n",
    "                    elem = []\n",
    "                    for ind in cols:\n",
    "                        elem.append(line[ind])\n",
    "                    if sum([x == 'NaN' for x in elem]) == 0:\n",
    "                        data.append([float(x) / 1000 for x in elem[:-1]])\n",
    "                        labels.append(labelToId[elem[-1]])\n",
    "\n",
    "        return {'inputs': np.asarray(data), 'targets': np.asarray(labels, dtype=int)+1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_reader_replace:\n",
    "    def __init__(self, dataset):\n",
    "        if dataset =='opp':\n",
    "            self.data, self.idToLabel = self.readOpportunity()\n",
    "            self.save_data_csv(dataset)\n",
    "            self.save_data(dataset)\n",
    "        else:\n",
    "            print('Not supported yet')\n",
    "            sys.exit(0)\n",
    "\n",
    "    def save_data_csv(self, dataset):\n",
    "        if dataset == 'opp':\n",
    "            for key in self.data:\n",
    "                for field in self.data[key]:\n",
    "                    np.savetxt('data_replace_'+field+'.csv', self.data[key][field], delimiter=',')\n",
    "            print('Saved in csv.')\n",
    "        else:\n",
    "            print('Not supported yet')\n",
    "            sys.exit(0)\n",
    "\n",
    "    def save_data(self, dataset):\n",
    "        if dataset == 'opp':\n",
    "            f = h5py.File('opportunity_replace.h5')\n",
    "            for key in self.data:\n",
    "                f.create_group(key)\n",
    "                for field in self.data[key]:\n",
    "                    f[key].create_dataset(field, data=self.data[key][field])\n",
    "            f.close()\n",
    "            print('Done.')\n",
    "            #np.savetxt(\"test.csv\", f, '%g', ',')\n",
    "        else:\n",
    "            print('Not supported yet')\n",
    "            sys.exit(0)\n",
    "\n",
    "\n",
    "    @property\n",
    "    def train(self):\n",
    "        return self.data['train']\n",
    "\n",
    "    @property\n",
    "    def test(self):\n",
    "        return self.data['test']\n",
    "\n",
    "    def readOpportunity(self):\n",
    "        files = {\n",
    "            'train': ['S1-ADL1.dat','S1-ADL3.dat', 'S1-ADL4.dat', 'S1-ADL5.dat', 'S1-Drill.dat', 'S2-ADL1.dat', 'S2-ADL2.dat', 'S2-ADL5.dat', 'S2-Drill.dat', 'S3-ADL1.dat', 'S3-ADL2.dat', 'S3-ADL5.dat', 'S3-Drill.dat', 'S4-ADL1.dat', 'S4-ADL2.dat', 'S4-ADL3.dat', 'S4-ADL4.dat', 'S4-ADL5.dat', 'S4-Drill.dat'],\n",
    "            'test': ['S2-ADL3.dat', 'S2-ADL4.dat','S3-ADL3.dat', 'S3-ADL4.dat']\n",
    "        }\n",
    "        #names are from label_legend.txt of Opportunity dataset\n",
    "        #except 0-ie Other, which is an additional label\n",
    "        label_map = [\n",
    "            (0,      'Other'),\n",
    "            (406516, 'Open Door 1'),\n",
    "            (406517, 'Open Door 2'),\n",
    "            (404516, 'Close Door 1'),\n",
    "            (404517, 'Close Door 2'),\n",
    "            (406520, 'Open Fridge'),\n",
    "            (404520, 'Close Fridge'),\n",
    "            (406505, 'Open Dishwasher'),\n",
    "            (404505, 'Close Dishwasher'),\n",
    "            (406519, 'Open Drawer 1'),\n",
    "            (404519, 'Close Drawer 1'),\n",
    "            (406511, 'Open Drawer 2'),\n",
    "            (404511, 'Close Drawer 2'),\n",
    "            (406508, 'Open Drawer 3'),\n",
    "            (404508, 'Close Drawer 3'),\n",
    "            (408512, 'Clean Table'),\n",
    "            (407521, 'Drink from Cup'),\n",
    "            (405506, 'Toggle Switch')\n",
    "        ]\n",
    "        labelToId = {str(x[0]): i for i, x in enumerate(label_map)}\n",
    "        idToLabel = [x[1] for x in label_map]\n",
    "\n",
    "        cols = [\n",
    "            37, 38, 39, 40, 41, 42, 43, 44, 45, 50, 51, 52, 53, 54, 55, 56, 57, 58,63, 64, 65, 66, 67, 68, 69, 70, 71, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
    "            89, 90, 91, 92, 93, 94, 95, 96, 97, 102, 103, 104, 105, 106, 107, 108,109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
    "            124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 249\n",
    "            ]\n",
    "\n",
    "        data = {dataset: self.readOpportunityFilesRaplace(files[dataset], cols, labelToId)\n",
    "                for dataset in ('train', 'test')}\n",
    "\n",
    "        return data, idToLabel\n",
    "\n",
    "#this is from https://github.com/nhammerla/deepHAR/tree/master/data and it is an opportunity Challenge reader. It is a python translation one\n",
    "#for the official one provided by the dataset publishers in Matlab.\n",
    "    def readOpportunityFilesRaplace(self, filelist, cols, labelToId):\n",
    "        data = []\n",
    "        labels = []\n",
    "        for i, filename in enumerate(filelist):\n",
    "            print('Reading file %d of %d' % (i+1, len(filelist)))\n",
    "            with open('/Users/JinWei/Downloads/OpportunityUCIDataset/dataset/%s' % filename, 'r') as f:\n",
    "                reader = csv.reader(f, delimiter=' ')\n",
    "                pre_line = next(reader)\n",
    "                pre_line = [0 if x == 'NaN' else x for x in pre_line]\n",
    "                while(True):\n",
    "                    try:\n",
    "                        cur_line = next(reader)\n",
    "                        elem = []\n",
    "                        for ind in cols:\n",
    "                            if cur_line[ind] == 'NaN':\n",
    "                                cur_line[ind] = pre_line[ind]\n",
    "                            elem.append(cur_line[ind])\n",
    "                        pre_line = cur_line\n",
    "                        data.append([float(x) / 1000 for x in elem[:-1]])\n",
    "                        labels.append(labelToId[elem[-1]])\n",
    "\n",
    "                        if 'NaN' in elem:\n",
    "                            print(elem)\n",
    "                    except StopIteration:\n",
    "                        break\n",
    "        return {'inputs': np.asarray(data), 'targets': np.asarray(labels, dtype=int)+1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_reader_remove_replace:\n",
    "    def __init__(self, dataset):\n",
    "        if dataset =='opp':\n",
    "            self.data, self.idToLabel = self.readOpportunity()\n",
    "            self.save_data_csv(dataset)\n",
    "            self.save_data(dataset)\n",
    "        else:\n",
    "            print('Not supported yet')\n",
    "            sys.exit(0)\n",
    "\n",
    "    def save_data_csv(self, dataset):\n",
    "        if dataset == 'opp':\n",
    "            for key in self.data:\n",
    "                for field in self.data[key]:\n",
    "                    np.savetxt('data_'+field+'.csv', self.data[key][field], delimiter=',')\n",
    "            print('Saved in csv.')\n",
    "        else:\n",
    "            print('Not supported yet')\n",
    "            sys.exit(0)\n",
    "\n",
    "    def save_data(self, dataset):\n",
    "        if dataset == 'opp':\n",
    "            f = h5py.File('opportunity_replace_remove_test.h5')\n",
    "            for key in self.data:\n",
    "                f.create_group(key)\n",
    "                for field in self.data[key]:\n",
    "                    f[key].create_dataset(field, data=self.data[key][field])\n",
    "            f.close()\n",
    "            print('Saved in h5py.')\n",
    "        else:\n",
    "            print('Not supported yet')\n",
    "            sys.exit(0)\n",
    "\n",
    "    @property\n",
    "    def train(self):\n",
    "        return self.data['train']\n",
    "\n",
    "    @property\n",
    "    def test(self):\n",
    "        return self.data['test']\n",
    "\n",
    "    def readOpportunity(self):\n",
    "        files = {\n",
    "            'train': ['S1-ADL1.dat','S1-ADL3.dat', 'S1-ADL4.dat', 'S1-ADL5.dat', 'S1-Drill.dat', 'S2-ADL1.dat', 'S2-ADL2.dat', 'S2-ADL5.dat', 'S2-Drill.dat', 'S3-ADL1.dat', 'S3-ADL2.dat', 'S3-ADL5.dat', 'S3-Drill.dat', 'S4-ADL1.dat', 'S4-ADL2.dat', 'S4-ADL3.dat', 'S4-ADL4.dat', 'S4-ADL5.dat', 'S4-Drill.dat'],\n",
    "            'test': ['S2-ADL3.dat', 'S2-ADL4.dat','S3-ADL3.dat', 'S3-ADL4.dat']\n",
    "        }\n",
    "        #names are from label_legend.txt of Opportunity dataset\n",
    "        #except 0-ie Other, which is an additional label\n",
    "        label_map = [\n",
    "            (0,      'Other'),\n",
    "            (406516, 'Open Door 1'),\n",
    "            (406517, 'Open Door 2'),\n",
    "            (404516, 'Close Door 1'),\n",
    "            (404517, 'Close Door 2'),\n",
    "            (406520, 'Open Fridge'),\n",
    "            (404520, 'Close Fridge'),\n",
    "            (406505, 'Open Dishwasher'),\n",
    "            (404505, 'Close Dishwasher'),\n",
    "            (406519, 'Open Drawer 1'),\n",
    "            (404519, 'Close Drawer 1'),\n",
    "            (406511, 'Open Drawer 2'),\n",
    "            (404511, 'Close Drawer 2'),\n",
    "            (406508, 'Open Drawer 3'),\n",
    "            (404508, 'Close Drawer 3'),\n",
    "            (408512, 'Clean Table'),\n",
    "            (407521, 'Drink from Cup'),\n",
    "            (405506, 'Toggle Switch')\n",
    "        ]\n",
    "        labelToId = {str(x[0]): i for i, x in enumerate(label_map)}\n",
    "        idToLabel = [x[1] for x in label_map]\n",
    "\n",
    "        cols = [\n",
    "            37, 38, 39, 40, 41, 42, 43, 44, 45, 50, 51, 52, 53, 54, 55, 56, 57, 58,63, 64, 65, 66, 67, 68, 69, 70, 71, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
    "            89, 90, 91, 92, 93, 94, 95, 96, 97, 102, 103, 104, 105, 106, 107, 108,109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
    "            124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 249\n",
    "            ]\n",
    "\n",
    "        data = {dataset: self.readOpportunityFilesRaplace(files[dataset], cols, labelToId) for dataset in ('train', 'test')}\n",
    "\n",
    "        return data, idToLabel\n",
    "\n",
    "#this is from https://github.com/nhammerla/deepHAR/tree/master/data and it is an opportunity Challenge reader. It is a python translation one\n",
    "#for the official one provided by the dataset publishers in Matlab.\n",
    "    def readOpportunityFilesRaplace(self, filelist, cols, labelToId):\n",
    "        data = []\n",
    "        labels = []\n",
    "        for i, filename in enumerate(filelist):\n",
    "            print('Reading file %d of %d' % (i+1, len(filelist)))\n",
    "            with open('/Users/JinWei/Downloads/OpportunityUCIDataset/dataset/%s' % filename, 'r') as f:\n",
    "                reader = csv.reader(f, delimiter=' ')\n",
    "                pre_line = next(reader)\n",
    "                pre_line = [0 if x == 'NaN' else x for x in pre_line]\n",
    "                while(True):\n",
    "                    try:\n",
    "                        cur_line = next(reader)\n",
    "                        elem = []\n",
    "                        nan_cnt = 0\n",
    "                        for ind in cols:\n",
    "                            if cur_line[ind] == 'NaN':\n",
    "                                nan_cnt += 1\n",
    "                                cur_line[ind] = pre_line[ind]\n",
    "                            elem.append(cur_line[ind])\n",
    "                        if nan_cnt <= 15:\n",
    "                            pre_line = cur_line\n",
    "                            data.append([float(x) / 1000 for x in elem[:-1]])\n",
    "                            labels.append(labelToId[elem[-1]])\n",
    "                        else:\n",
    "                            print(nan_cnt)\n",
    "                    except StopIteration:\n",
    "                        break\n",
    "        return {'inputs': np.asarray(data), 'targets': np.asarray(labels, dtype=int)+1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print('Reading opportunity dataset')\n",
    "    dr = data_reader_remove('opp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
